{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import *\n",
    "\n",
    "\n",
    "nz = 100\n",
    "ngf = 64\n",
    "nc = 3\n",
    "ndf = 64\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "lrG = 0.0002\n",
    "lrD = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "image_size = 128\n",
    "data_root = \"data/face\"\n",
    "output_dir = \"output\"\n",
    "dataset = \"face\"\n",
    "model_name = \"DCGAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b507abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74c165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(nz, ngf, nc)\n",
    "\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e9a0e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n",
      "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
      "              ReLU-3            [-1, 512, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n",
      "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
      "              ReLU-6            [-1, 256, 8, 8]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "  ConvTranspose2d-13           [-1, 32, 64, 64]          32,768\n",
      "      BatchNorm2d-14           [-1, 32, 64, 64]              64\n",
      "             ReLU-15           [-1, 32, 64, 64]               0\n",
      "  ConvTranspose2d-16          [-1, 3, 128, 128]           1,536\n",
      "             Tanh-17          [-1, 3, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 3,608,000\n",
      "Trainable params: 3,608,000\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.56\n",
      "Params size (MB): 13.76\n",
      "Estimated Total Size (MB): 20.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(netG, input_size=(100, 1, 1), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0977a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (13): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (14): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator(nc, ndf)\n",
    "\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66016ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           3,072\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          65,536\n",
      "         LeakyReLU-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5          [-1, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8            [-1, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-9            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-10            [-1, 256, 8, 8]               0\n",
      "           Conv2d-11            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-12            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-13            [-1, 512, 4, 4]               0\n",
      "           Conv2d-14              [-1, 1, 1, 1]           8,192\n",
      "          Sigmoid-15              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,831,104\n",
      "Trainable params: 2,831,104\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 6.31\n",
      "Params size (MB): 10.80\n",
      "Estimated Total Size (MB): 17.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(netD, input_size=(3, 128, 128), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = DCGAN(nz, ngf, ndf, nc, batch_size, epochs, lrG, lrD, beta1, beta2, \\\n",
    "    image_size, data_root, output_dir, dataset, model_name, gpu_mode=True)\n",
    "\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2bc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabcb8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd8abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32f380d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell_forward(xt, a_prev, c_prev, parameters):\n",
    "    \"\"\"\n",
    "    Implement a single forward step of the LSTM-cell as described in Figure (4)\n",
    "\n",
    "    Arguments:\n",
    "    xt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
    "    a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    c_prev -- Memory state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)\n",
    "                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
    "                        Wc -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
    "                        bc --  Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
    "                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        bo --  Bias of the output gate, numpy array of shape (n_a, 1)\n",
    "                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "                        \n",
    "    Returns:\n",
    "    a_next -- next hidden state, of shape (n_a, m)\n",
    "    c_next -- next memory state, of shape (n_a, m)\n",
    "    yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\n",
    "    cache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters)\n",
    "    \n",
    "    Note: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilde),\n",
    "          c stands for the memory value\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve parameters from \"parameters\"\n",
    "    Wf = parameters[\"Wf\"]\n",
    "    bf = parameters[\"bf\"]\n",
    "    Wi = parameters[\"Wi\"]\n",
    "    bi = parameters[\"bi\"]\n",
    "    Wc = parameters[\"Wc\"]\n",
    "    bc = parameters[\"bc\"]\n",
    "    Wo = parameters[\"Wo\"]\n",
    "    bo = parameters[\"bo\"]\n",
    "    Wy = parameters[\"Wy\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    # Retrieve dimensions from shapes of xt and Wy\n",
    "    n_x, m = xt.shape\n",
    "    n_y, n_a = Wy.shape\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Concatenate a_prev and xt (≈3 lines)\n",
    "    concat = np.zeros((n_a + n_x, m))\n",
    "    concat[: n_a, :] = a_prev\n",
    "    concat[n_a :, :] = xt\n",
    "\n",
    "    # Compute values for ft, it, cct, c_next, ot, a_next using the formulas given figure (4) (≈6 lines)\n",
    "    ft = sigmoid(np.dot(Wf, concat) + bf)\n",
    "    print(ft)\n",
    "    it = sigmoid(np.dot(Wi, concat) + bi)\n",
    "    print(it)\n",
    "    cct = np.tanh(np.dot(Wc, concat) + bc)\n",
    "    print(cct)\n",
    "    c_next = ft * c_prev + it * cct \n",
    "    ot = sigmoid(np.dot(Wo, concat) + bo)\n",
    "    a_next = ot * np.tanh(c_next)\n",
    "    \n",
    "    # Compute prediction of the LSTM cell (≈1 line)\n",
    "    yt_pred = np.dot(Wy, a_next) + by\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # store values needed for backward propagation in cache\n",
    "    cache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)\n",
    "\n",
    "    return a_next, c_next, yt_pred, cache, ft, it, cct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "864633af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "xt = np.array([[2]])\n",
    "Wy = np.array([[1,-1],[1,0]])\n",
    "a_prev = np.array([[0],[1]])\n",
    "\n",
    "n_x, m = xt.shape\n",
    "n_y, n_a = Wy.shape\n",
    "\n",
    "### START CODE HERE ###\n",
    "    # Concatenate a_prev and xt (≈3 lines)\n",
    "concat = np.zeros((n_a + n_x, m))\n",
    "print(concat.shape)\n",
    "concat[: n_a, :] = a_prev\n",
    "concat[n_a :, :] = xt\n",
    "print(concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26f8769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26894142]\n",
      " [0.5       ]]\n",
      "[[0.88079708]\n",
      " [0.26894142]]\n",
      "[[-0.76159416]\n",
      " [ 0.        ]]\n",
      "a_next =  [[-0.2789329 ]\n",
      " [ 0.45380542]]\n",
      "a_next.shape =  (2, 1)\n",
      "c_next =  [[-0.40186849]\n",
      " [ 0.5       ]]\n",
      "c_next.shape =  (2, 1)\n",
      "yt = [[0.26726168]\n",
      " [1.7210671 ]]\n",
      "yt.shape =  (2, 1)\n",
      "cache = (array([[-0.2789329 ],\n",
      "       [ 0.45380542]]), array([[-0.40186849],\n",
      "       [ 0.5       ]]), array([[0],\n",
      "       [1]]), array([[1],\n",
      "       [1]]), array([[0.26894142],\n",
      "       [0.5       ]]), array([[0.88079708],\n",
      "       [0.26894142]]), array([[-0.76159416],\n",
      "       [ 0.        ]]), array([[0.73105858],\n",
      "       [0.98201379]]), array([[2]]), {'Wf': array([[1, 0, 1],\n",
      "       [0, 1, 0]]), 'Wi': array([[ 1,  1, -2],\n",
      "       [ 0,  1,  0]]), 'Wo': array([[ 0,  0,  1],\n",
      "       [-2,  1,  0]]), 'Wc': array([[1, 0, 1],\n",
      "       [0, 1, 0]]), 'Wy': array([[ 1, -1],\n",
      "       [ 1,  0]]), 'bf': array([[-3],\n",
      "       [-1]]), 'bi': array([[ 5],\n",
      "       [-2]]), 'bo': array([[-1],\n",
      "       [ 3]]), 'bc': array([[-3],\n",
      "       [-1]]), 'by': array([[1],\n",
      "       [2]])})\n",
      "len(cache) =  10\n",
      "********************\n",
      "ft =  [[0.26894142]\n",
      " [0.5       ]]\n",
      "(2, 1)\n",
      "it =  [[0.88079708]\n",
      " [0.26894142]]\n",
      "(2, 1)\n",
      "cct =  [[-0.76159416]\n",
      " [ 0.        ]]\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xt = np.array([[2]])\n",
    "a_prev = np.array([[0],[1]])\n",
    "c_prev = np.array([[1],[1]])\n",
    "Wf = np.array([[1,0,1],[0,1,0]])\n",
    "bf = np.array([[-3],[-1]])\n",
    "Wi = np.array([[1,1,-2],[0,1,0]])\n",
    "bi = np.array([[5],[-2]])\n",
    "Wo = np.array([[0,0,1],[-2,1,0]])\n",
    "bo = np.array([[-1],[3]])\n",
    "Wc = np.array([[1,0,1],[0,1,0]])\n",
    "bc = np.array([[-3],[-1]])\n",
    "Wy = np.array([[1,-1],[1,0]])\n",
    "by = np.array([[1],[2]])\n",
    "\n",
    "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "\n",
    "a_next, c_next, yt, cache, ft, it, cct = lstm_cell_forward(xt, a_prev, c_prev, parameters)\n",
    "print(\"a_next = \", a_next)\n",
    "print(\"a_next.shape = \", c_next.shape)\n",
    "print(\"c_next = \", c_next)\n",
    "print(\"c_next.shape = \", c_next.shape)\n",
    "print(\"yt =\", yt)\n",
    "print(\"yt.shape = \", yt.shape)\n",
    "print(\"cache =\", cache)\n",
    "print(\"len(cache) = \", len(cache))\n",
    "print(\"*\"*20)\n",
    "print(\"ft = \", ft)\n",
    "print(ft.shape)\n",
    "print(\"it = \", it)\n",
    "print(it.shape)\n",
    "print(\"cct = \", cct)\n",
    "print(cct.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7f1be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40186849]\n",
      " [ 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "print(ft*c_prev+it*cct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17f9a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73105858]\n",
      " [0.98201379]]\n"
     ]
    }
   ],
   "source": [
    "ot = sigmoid(np.dot(Wo, concat) + bo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ad52279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38154658]\n",
      " [ 0.46211716]]\n"
     ]
    }
   ],
   "source": [
    "print(np.tanh(c_next))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
